# Chinese-public-judgments
## get public judgments form China court easily

# 裁判文书网自动化文书获取工具——仅供学习使用，请勿复用生产环境，谢谢配合！
** 本项目所有者对代码创作和使用享有最终解释权，禁止恶意攻击裁判文书网的任何数据！仅供学习参考！！ **

## 1. 项目简介
本项目是一个**极致安全、可高度个性化定制**的自动化采集工具，面向中国裁判文书网（wenshu.court.gov.cn）。
- 支持全国任意地区、法院、案由、日期等多维度个性化采集
- 完全模拟真实用户浏览、点击、输入、翻页、阅读等行为
- 支持高级检索、筛选、分页、文书下载与清洗
- 每天、每页、每文书均有极长且不规律的延时，夜间自动暂停，偶尔跳过，指纹/UA/分辨率定期切换
- 自动检测验证码/异常页面并长时间暂停，最大限度降低被识别为自动化风险
- 支持断点续采、去重、结构化存储

> **上海市采集只是一个示例，您可根据实际需求采集全国任意地区、法院、案由、时间段等。**

## 2. 目录结构说明
```
├── README.md                # 项目说明文档
├── requirements.txt         # 依赖包列表
├── jiagou.md                # 架构设计文档
├── browser_simulator.py     # 浏览器与反检测核心
├── document_cleaner.py      # 文书内容清洗与保存
├── collect_shanghai_documents.py # 正式采集主脚本（可个性化修改采集目标）
├── test_collection_system.py     # 测试采集主脚本
├── 文书/                    # 按日期存放清洗后的文书txt
├── URL列表/                 # 按日期存放采集到的文书URL
└── ...（其他辅助文件）
```

## 3. 依赖环境与安装方法
- 推荐环境：Python 3.8+，Windows 10/11
- 依赖包：见 requirements.txt

安装依赖：
```bash
pip install -r requirements.txt
# 首次使用playwright需初始化浏览器驱动：
python -m playwright install
```

## 4. 使用说明
### 4.1 测试采集（建议先运行）
```bash
python test_collection_system.py
```
- 仅采集少量日期/文书，验证流程与反检测效果

### 4.2 正式采集
```bash
python collect_shanghai_documents.py
```
- 默认采集上海市近三年全部文书（可自定义采集目标，见下文）
- 支持断点续采，已采集日期自动跳过

### 4.3 个性化采集说明
本工具支持**灵活定制采集目标**，包括但不限于：
- 地区/法院：如采集北京、广东、江苏、或指定法院
- 案由：如只采集“合同纠纷”、“刑事案件”等
- 日期范围：如采集近一年、近五年、任意时间段
- 其他高级检索条件：如案件类型、文书类型、关键词等

#### 个性化采集参数修改方法
1. **修改主脚本（如 collect_shanghai_documents.py）中的相关参数**：
   - `region`、`court`、`case_type`、`date_range` 等变量
   - 相关 Playwright 操作步骤（如选择不同地区、法院、案由等）
2. **举例**：
   - 采集北京地区：将“上海市”相关选择器/文本替换为“北京市”
   - 采集“合同纠纷”案由：在高级检索中自动选择案由字段
   - 采集指定法院：在地域及法院筛选中选择目标法院
3. **如需采集多个地区/案由/法院**，可循环调用采集流程或批量配置参数

#### 代码片段示例
```python
# 以采集“北京市”为例
self.select_region('北京市')  # 替换为目标地区
# 采集“合同纠纷”案由
self.select_case_reason('合同纠纷')
# 采集指定法院
self.select_court('北京市第一中级人民法院')
```

### 4.4 参数与注意事项
- 所有采集均为**极致安全模式** 防止误判攻击裁判文书网，速度极慢（单日采集需数小时，三年全量需数月）
- 运行时请保持网络畅通，勿频繁中断
- 采集结果保存在 `文书/日期/` 和 `URL列表/` 目录下
- 如遇验证码/异常，程序会自动暂停后重试

## 5. 反检测策略简述
- **极长且不规律延时**：每页20~60秒，每文书30~90秒，每天3~10分钟，偶尔长时间停顿
- **复杂人类行为模拟**：鼠标多次移动、滚动、点击空白、偶尔点开无关链接、偶尔刷新、偶尔输入错误再修正
- **夜间自动暂停**：0:00~7:00自动休眠
- **指纹/UA/分辨率/语言定期切换**：每1~3天自动更换
- **偶尔跳过**：模拟人类疏漏，偶尔跳过某天/页/文书
- **验证码/异常检测**：遇到验证码或异常页面自动暂停30~120分钟

## 6. 常见问题与建议
- **Q: 如何个性化采集？**
  - 修改主脚本参数和选择器，支持采集全国任意地区、法院、案由、时间段等，详见“个性化采集说明”章节。
- **Q: 如何扩展采集范围？**
  - 可批量配置参数或循环调用采集流程，实现多地区/多案由/多法院采集。
- **Q: 采集速度太慢怎么办？**
  - 本项目以安全为最高优先级，如需提速可适当缩短延时，但风险自负。
- **Q: 运行中断后如何恢复？**
  - 重新运行脚本即可，已采集日期会自动跳过。
- **Q: 如何调整反检测参数？**
  - 修改 browser_simulator.py 和主脚本中的延时区间、行为概率等参数。
- **Q: 遇到验证码/异常怎么办？**
  - 程序会自动暂停并重试，无需人工干预。
- **Q: 支持多线程/分布式吗？**
  - 当前为单进程极致安全模式，不建议并发。

## 7. 致谢
- 感谢 Playwright、BeautifulSoup4 等开源项目
- 感谢所有为本项目提出建议和测试的同仁

---
如有问题或建议，欢迎联系维护者！ 仅供学习参阅！！
